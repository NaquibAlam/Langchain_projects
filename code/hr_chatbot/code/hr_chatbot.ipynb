{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc559bda-0fcc-409f-b473-7140c7fadaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/libraries/llm_exp_1/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.27) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import DeepLake\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langchain.llms import GPT4All\n",
    "# from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import validator, field_validator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "import openai\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import cohere\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain_community.llms import Cohere\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain import LLMMathChain\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591c2d6a-a29f-4ccb-a568-abf4f8856527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c36b354-e636-467b-80ac-146fb22e663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"]= \"\"\n",
    "os.environ[\"GOOGLE_CSE_ID\"]= \"\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]= \"\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"\"\n",
    "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"\"\n",
    "os.environ[\"SERPAPI_API_KEY\"]= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baded54c-6659-4153-a69e-fc22dd8abdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ada =  OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "chromadb_collection_name= \"oepnai_ada_hr_chatbot_collection\"\n",
    "policy_doc_filepath= \"/home/jupyter/self_learning/Langchain/code/hr_chatbot/data/hr_policy.txt\"\n",
    "emp_data_filepath= \"/home/jupyter/self_learning/Langchain/code/hr_chatbot/data/employee_data.csv\"\n",
    "user = 'Alexander Verdad' # set user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6266ecc1-eeab-4807-8a4d-7b1226fd01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load documents from a file\n",
    "def load_policy_docs(filename):\n",
    "    # Create an empty list to hold the documents\n",
    "    docs = []\n",
    "    try:\n",
    "        # Load the file using the TextLoader class and UTF-8 encoding\n",
    "        loader = TextLoader(filename, encoding='utf-8')\n",
    "        # Split the loaded file into separate documents and add them to the list of documents\n",
    "        docs.extend(loader.load_and_split())\n",
    "    except Exception as e:\n",
    "        # If an error occurs during loading, ignore it and return an empty list of documents\n",
    "        pass\n",
    "    # Return the list of documents\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08bf819-655f-4492-a98d-4e0e8cb2c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_policy_docs(docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20, length_function=len)\n",
    "    return text_splitter.split_documents(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1df95df-49e9-4019-8315-6adee2548093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors_into_db(documents):\n",
    "    client = chromadb.Client()\n",
    "    db = Chroma.from_documents(documents, embed_ada, client=client, collection_name=chromadb_collection_name)\n",
    "    print(\"There are\", db._collection.count(), \"in the collection\")\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef9b75a-c2a8-4e87-8eed-4678037e5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 in the collection\n"
     ]
    }
   ],
   "source": [
    "# Define the main function\n",
    "client = chromadb.Client()\n",
    "client.delete_collection(name=chromadb_collection_name)\n",
    "def main():\n",
    "    # Load the content from the policy file\n",
    "    docs = load_policy_docs(policy_doc_filepath)\n",
    "    # Split the content into individual documents\n",
    "    docs = split_policy_docs(docs)\n",
    "    # Create a chromadb database with the given embedding function\n",
    "    oepnai_ada_hr_chatbot_db = load_vectors_into_db(docs)\n",
    "\n",
    "# Call the main function if this script is being run as the main program\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8579e8e6-4f60-4f9a-9c8b-d35e1aea9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = chromadb.Client()\n",
    "# collection = client.get_collection(name=chromadb_collection_name, embedding_function=embed_ada)\n",
    "# print(\"There are\", collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a156813c-9b56-4198-ae57-3e27ebdce368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.get(include=['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8ea4ac-8115-4518-a294-9de11668cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embeddings and DeepLake database\n",
    "def load_embeddings_and_database(collection_name):\n",
    "    client = chromadb.Client()\n",
    "    db = Chroma(client = client, collection_name = collection_name, embedding_function=embed_ada)\n",
    "#     db = client.get_collection(name=collection_name, embedding_function=embed_ada)\n",
    "    print(\"There are\", db._collection.count(), \"in the collection\")\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0f19e6a-7474-44de-94d9-90b80ccd1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(db):\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "    # initialize vectorstore retriever object\n",
    "    timekeeping_policy = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "\n",
    "    df = pd.read_csv(emp_data_filepath) # load employee_data.csv as dataframe\n",
    "    python = PythonAstREPLTool(locals={\"df\": df}) # set access of python_repl tool to the dataframe\n",
    "\n",
    "    # create calculator tool\n",
    "    calculator = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "    df_columns = df.columns.to_list() # print column names of df\n",
    "\n",
    "    # prep the (tk policy) vectordb retriever, the python_repl(with df access) and langchain calculator as tools for the agent\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name = \"Timekeeping Policies\",\n",
    "            func=timekeeping_policy.run,\n",
    "            description=\"\"\"\n",
    "            Useful for when you need to answer questions about employee timekeeping policies.\n",
    "\n",
    "            <user>: What is the policy on unused vacation leave?\n",
    "            <assistant>: I need to check the timekeeping policies to answer this question.\n",
    "            <assistant>: Action: Timekeeping Policies\n",
    "            <assistant>: Action Input: Vacation Leave Policy - Unused Leave\n",
    "            ...\n",
    "            \"\"\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name = \"Employee Data\",\n",
    "            func=python.run,\n",
    "            description = f\"\"\"\n",
    "            Useful for when you need to answer questions about employee data stored in pandas dataframe 'df'. \n",
    "            Run python pandas operations on 'df' to help you get the right answer.\n",
    "            'df' has the following columns: {df_columns}\n",
    "\n",
    "            <user>: How many Sick Leave do I have left?\n",
    "            <assistant>: df[df['name'] == '{user}']['sick_leave']\n",
    "            <assistant>: You have n sick leaves left.              \n",
    "            \"\"\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name = \"Calculator\",\n",
    "            func=calculator.run,\n",
    "            description = f\"\"\"\n",
    "            Useful when you need to do math operations or arithmetic.\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # change the value of the prefix argument in the initialize_agent function. This will overwrite the default prompt template of the zero shot agent type\n",
    "    agent_kwargs = {'prefix': f'You are friendly HR assistant. You are tasked to assist the current user: {user} on questions related to HR. You have access to the following tools:'}\n",
    "\n",
    "\n",
    "    # initialize the LLM agent\n",
    "    agent = initialize_agent(tools, \n",
    "                             llm, \n",
    "                             agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                             verbose=True, \n",
    "                             agent_kwargs=agent_kwargs\n",
    "                             )\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48ca8681-c454-435b-ba9a-89e56362d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define q and a function for frontend\n",
    "def get_response(user_input):\n",
    "    db = load_embeddings_and_database(chromadb_collection_name)\n",
    "    agent= create_agent(db)\n",
    "    response = agent.run(user_input)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2c35901-776d-4bfb-b9a0-1c85c29ee6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 in the collection\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check the employee data to find the name and employee id of Alexander Verdad.\n",
      "Action: Employee Data\n",
      "Action Input: df[df['name'] == 'Alexander Verdad'][['employee_id', 'name']]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m   employee_id              name\n",
      "2      1005676  Alexander Verdad\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Your name is Alexander Verdad and your employee id is 1005676.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_input= \"What is my name and employee id?\"\n",
    "response= get_response(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9737b7ed-b137-4d75-af19-b5eb5b70e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 in the collection\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check the timekeeping policies to answer this question.\n",
      "Action: Timekeeping Policies\n",
      "Action Input: Vacation Leave Policy - Probationary Employees\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mProbationary employees are not eligible for Vacation Leave according to the company's policy. They are only eligible for Sick Leave at a reduced rate and are not entitled to Vacation Leave or Service Incentive Leave during their probation period.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Probationary employees are not allowed to have vacation leaves.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Probationary employees are not allowed to have vacation leaves.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('Are employees on probation allowed to have vacation leaves?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b95021-8291-4e38-aa17-77268cf384e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 in the collection\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check the employee data for Alexander Verdad to see how many vacation leaves he has left and then refer to the timekeeping policies for the policy on unused vacation leaves.\n",
      "Action: Employee Data\n",
      "Action Input: df[df['name'] == 'Alexander Verdad']['vacation_leave']\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2    45\n",
      "Name: vacation_leave, dtype: int64\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to check the timekeeping policies for the policy on unused vacation leaves.\n",
      "Action: Timekeeping Policies\n",
      "Action Input: Vacation Leave Policy - Unused Leave\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mUnused Vacation Leave can be carried over to the next year, but the total accumulated leave should not exceed 30 days. Any excess leave will be forfeited. Additionally, unused Vacation Leave can be encashed at the end of the year at the basic salary rate. The encashment rate is calculated as the basic salary divided by 30 days, multiplied by the number of unused leaves to be encashed.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: Alexander Verdad has 45 vacation leaves left. Unused vacation leave can be carried over to the next year, but the total accumulated leave should not exceed 30 days. Any excess leave will be forfeited. Unused vacation leave can also be encashed at the end of the year at the basic salary rate.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Alexander Verdad has 45 vacation leaves left. Unused vacation leave can be carried over to the next year, but the total accumulated leave should not exceed 30 days. Any excess leave will be forfeited. Unused vacation leave can also be encashed at the end of the year at the basic salary rate.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"How many vacation leaves do I have left and what is the policy on unused VLs?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a6f87fa-d59f-4f17-b618-32aabf2df4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 in the collection\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the amount based on the employee's basic pay and the number of unused vacation leaves.\n",
      "Action: Employee Data\n",
      "Action Input: df[df['name'] == 'Alexander Verdad'][['basic_pay_in_php', 'vacation_leave']]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m   basic_pay_in_php  vacation_leave\n",
      "2             15000              45\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to calculate the total amount for unused vacation leaves.\n",
      "Action: Calculator\n",
      "Action Input: 15000 * 45\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "15000 * 45\u001b[32;1m\u001b[1;3m```text\n",
      "15000 * 45\n",
      "```\n",
      "...numexpr.evaluate(\"15000 * 45\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m675000\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mAnswer: 675000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: If you encash all your unused vacation leaves, you will be paid 675,000 PHP.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'If you encash all your unused vacation leaves, you will be paid 675,000 PHP.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"How much will I be paid if I encash all my unused vacation leaves?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071d608-b5ff-4a3c-8ffe-3623b590a98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
